{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uosaW7f21FzK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import os"
      ],
      "metadata": {
        "id": "zlYj7mJC31fM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flowers_root = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "metadata": {
        "id": "WkOB8ZE25-uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8f1877-06f2-4727-844c-a0a9c1444a04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RFnaH98dXKyr",
        "outputId": "f309dc75-5a35-4da4-deda-f578c04ff536"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/flower_photos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4EaNIi7O_V-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( len(os.listdir('/root/.keras/datasets/flower_photos')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5HBEIE56DkZ",
        "outputId": "5241831e-75fa-4778-e4ee-da997b7c8f03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( len(os.listdir('/root/.keras/datasets/flower_photos/daisy')))\n",
        "print( len(os.listdir('/root/.keras/datasets/flower_photos/dandelion')))\n",
        "print( len(os.listdir('/root/.keras/datasets/flower_photos/roses')))\n",
        "print( len(os.listdir('/root/.keras/datasets/flower_photos/sunflowers')))\n",
        "print( len(os.listdir('/root/.keras/datasets/flower_photos/tulips')))\n"
      ],
      "metadata": {
        "id": "ZdTc0TWM77tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894615fa-83db-4322-9def-03549d0a0f20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "633\n",
            "898\n",
            "641\n",
            "699\n",
            "799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        flowers_root,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "Wg__PtcOJHGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d76a9f3-40f8-4849-a693-c8cc5b99ba23"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XMNRnjuXoCX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)),\n",
        "layers.MaxPooling2D((2, 2)),\n",
        "layers.MaxPooling2D((2, 2)),\n",
        "layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "layers.MaxPooling2D((2, 2)),\n",
        "layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "layers.MaxPooling2D((2, 2)),\n",
        "layers.Flatten(),\n",
        "layers.Dense(512, activation='relu'),\n",
        "layers.Dense(5, activation='sigmoid')])"
      ],
      "metadata": {
        "id": "IrAe7udSBvc6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX2aRr1MXwzT",
        "outputId": "b2b439e9-47b2-4b52-aa8f-61c9223e42de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data batch shape: (20, 150, 150, 3)\n",
            "labels batch shape: (20, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHOzctihCEFS",
        "outputId": "1a36ced6-b756-44a8-ac67-4fa3289df11a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 74, 74, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 37, 37, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 35, 35, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 17, 17, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 7, 7, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3399813 (12.97 MB)\n",
            "Trainable params: 3399813 (12.97 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "uHAzxbmEhsbp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    elif epoch < 15:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "learning_rate_scheduler = LearningRateScheduler(scheduler, verbose=1)"
      ],
      "metadata": {
        "id": "4hq8h6AohnGr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "4KXDMAi0icmx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "metadata": {
        "id": "kzzwTbSiiN_4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch', period=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ngHawuiR1J",
        "outputId": "e73891b0-a049-4ade-cff8-a504840af32d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___________________________________________________"
      ],
      "metadata": {
        "id": "DA9Me_y0jtsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "seQEveHNjz3c"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logDir = \".\\\\fashion_mnist_log\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# logDir = \"fashion_mnist_log/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") #If you are using linux\n",
        "print(\"logDir: \", logDir)\n",
        "tensorboard_callback = TensorBoard(logDir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DrY6X-fjsts",
        "outputId": "a4f33ff9-026b-4cbb-951e-d144b3f73134"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logDir:  .\\fashion_mnist_log\\20240723-202127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "n3bP6G2BCeep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfc4464-35f0-4750-d290-b2ff8b004be2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NSfpWoliaJuR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hh = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=20,\n",
        "      callbacks=[learning_rate_scheduler,cp_callback,tensorboard_callback])"
      ],
      "metadata": {
        "id": "Ji_7vUn_RxFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14394612-4e21-4fdd-970e-bc53e4077cbb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-d8cec73d6c25>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hh = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 5s 42ms/step - loss: 1.4213 - acc: 0.3779 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 5s 51ms/step - loss: 1.1374 - acc: 0.5445 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 3/20\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.9950 - acc: 0.6111\n",
            "Epoch 3: saving model to training_2/cp-0003.ckpt\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 1.0024 - acc: 0.6090 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 5s 53ms/step - loss: 0.8703 - acc: 0.6470 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.8136 - acc: 0.6824 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 6/20\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.7366 - acc: 0.7136\n",
            "Epoch 6: saving model to training_2/cp-0006.ckpt\n",
            "100/100 [==============================] - 6s 56ms/step - loss: 0.7379 - acc: 0.7130 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.6768 - acc: 0.7437 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 0.6030 - acc: 0.7610 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5679 - acc: 0.7874\n",
            "Epoch 9: saving model to training_2/cp-0009.ckpt\n",
            "100/100 [==============================] - 6s 56ms/step - loss: 0.5679 - acc: 0.7874 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.4845 - acc: 0.8250 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.3183 - acc: 0.8980 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2327 - acc: 0.9251\n",
            "Epoch 12: saving model to training_2/cp-0012.ckpt\n",
            "100/100 [==============================] - 4s 45ms/step - loss: 0.2327 - acc: 0.9251 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.2293 - acc: 0.9211 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.2001 - acc: 0.9307 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1925 - acc: 0.9400\n",
            "Epoch 15: saving model to training_2/cp-0015.ckpt\n",
            "100/100 [==============================] - 5s 55ms/step - loss: 0.1925 - acc: 0.9400 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.1648 - acc: 0.9485 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.1650 - acc: 0.9447 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1571 - acc: 0.9538\n",
            "Epoch 18: saving model to training_2/cp-0018.ckpt\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.1571 - acc: 0.9538 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.1577 - acc: 0.9520 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 5s 53ms/step - loss: 0.1513 - acc: 0.9568 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **It needs data validation to check overfitting, but we use its generation and callbacks**"
      ],
      "metadata": {
        "id": "huHQm0grRtMm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDWo-mmZRwlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}